{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81eb8125",
      "metadata": {},
      "outputs": [],
      "source": [
        "from convert import *\n",
        "from function1 import *\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Dropout, GRU\n",
        "from keras.optimizers import Adam, SGD, Adagrad\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce960541",
      "metadata": {
        "id": "ce960541"
      },
      "outputs": [],
      "source": [
        "film_sayisi = 3\n",
        "window_size = 5\n",
        "films = list(range(film_sayisi))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62cde5ef",
      "metadata": {
        "id": "62cde5ef"
      },
      "outputs": [],
      "source": [
        "# Loading the dictionary\n",
        "with open(\"dictionary.txt\",\"r\",encoding=\"utf8\") as file:\n",
        "    dictionary = [string.replace(\"\\n\",\"\") for string in file.readlines()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe1e099b",
      "metadata": {
        "id": "fe1e099b"
      },
      "outputs": [],
      "source": [
        "# Creating scripts[][]\n",
        "scripts = []\n",
        "for j in films:\n",
        "    with open(f\"{j}_enc.txt\",\"r\") as file:\n",
        "        scripts.append(list(map(int,list(file.read().splitlines()))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bdaa07a",
      "metadata": {
        "id": "6bdaa07a"
      },
      "outputs": [],
      "source": [
        "# Turning int to [int]\n",
        "def func(liste):\n",
        "    return [[x] for x in liste]\n",
        "scripts = list(map(func,scripts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d13c8df1",
      "metadata": {
        "id": "d13c8df1"
      },
      "outputs": [],
      "source": [
        "# To categorical -> [0,0,0,...,1,...0,0,0]\n",
        "for j in films:\n",
        "    scripts[j] = to_categorical(scripts[j],num_classes=len(dictionary)+1,dtype=\"byte\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c65e44bd",
      "metadata": {
        "id": "c65e44bd"
      },
      "outputs": [],
      "source": [
        "# Creating inputs and outputs lists\n",
        "inputs = []\n",
        "outputs = []\n",
        "for j in films:\n",
        "    inputs.append(None)\n",
        "    outputs.append(None)\n",
        "\n",
        "\n",
        "# Creating sublists\n",
        "for j in films:\n",
        "    inputs[j],outputs[j] = create_sublists(scripts[j],window_size)\n",
        "\n",
        "\n",
        "# Removing [films] layer in lists\n",
        "inputs_temp = []\n",
        "for j in films:\n",
        "    for k in range(len(inputs[j])):\n",
        "        inputs_temp.append(inputs[j][k])\n",
        "inputs = inputs_temp\n",
        "del inputs_temp\n",
        "outputs_temp = []\n",
        "for j in films:\n",
        "    for k in range(len(outputs[j])):\n",
        "        outputs_temp.append(outputs[j][k])\n",
        "outputs = outputs_temp\n",
        "del outputs_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea018e8b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea018e8b",
        "outputId": "11845266-14d9-4543-aede-10b388fad4cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5, 7338) -> (7338,)\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]] -> [0 0 0 ... 0 0 0]\n",
            "(5, 7338) -> (7338,)\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]] -> [0 0 0 ... 0 0 0]\n",
            "(5, 7338) -> (7338,)\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]] -> [0 0 0 ... 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "for i in range(3):\n",
        "    print(f\"{np.shape(inputs[i])} -> {np.shape(outputs[i])}\")\n",
        "    print(f\"{inputs[i]} -> {outputs[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78287b3d",
      "metadata": {
        "id": "78287b3d"
      },
      "outputs": [],
      "source": [
        "# Creating train data and test data, x is for input and y is for output\n",
        "x_train, x_test, y_train, y_test = train_test_split(inputs, outputs, test_size=0.3, random_state=42)\n",
        "x_train = np.asarray(x_train)\n",
        "y_train = np.asarray(y_train)\n",
        "x_test = np.asarray(x_test)\n",
        "y_test = np.asarray(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d64f428",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d64f428",
        "outputId": "66fff380-d58c-43b2-e078-d5342e3f87f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(38906, 5, 7338)\n",
            "(38906, 7338)\n",
            "(16675, 5, 7338)\n",
            "(16675, 7338)\n",
            "\n",
            "\n",
            "7338\n",
            "[0 0 0 ... 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "print(np.shape(x_train))\n",
        "print(np.shape(y_train))\n",
        "print(np.shape(x_test))\n",
        "print(np.shape(y_test))\n",
        "\n",
        "for i in range(2):\n",
        "  print(\"\")\n",
        "\n",
        "print(len(x_train[0][0]))\n",
        "print(y_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3d3e2ef",
      "metadata": {
        "id": "e3d3e2ef"
      },
      "outputs": [],
      "source": [
        "# Creating model (ANN)\n",
        "window_size = 5\n",
        "model=Sequential([\n",
        "    Flatten(input_shape=(window_size, len(x_train[0][0]), 1),dtype=\"int8\"),\n",
        "    Dense(len(x_train[0][0]), activation=\"relu\"),\n",
        "    Dense(len(x_train[0][0]), activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Showing properties\n",
        "model.summary()\n",
        "\n",
        "# Setting the optimizer algorithm and compiling the model\n",
        "opt = Adagrad(learning_rate = 0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "print(\"Model ready\")\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=16)\n",
        "# Saving the model\n",
        "model.save(\"drive/MyDrive/Colab Notebooks/Dense_10epochs.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TIsfsv7g5tH3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIsfsv7g5tH3",
        "outputId": "b6723053-e5ff-4454-825d-d639a01e10d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_3 (LSTM)               (None, 5, 1000)           33356000  \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 5, 1000)           0         \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 5, 1000)           8004000   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 5, 1000)           0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 1000)              8004000   \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 1000)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7338)              7345338   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 56709338 (216.33 MB)\n",
            "Trainable params: 56709338 (216.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model2 ready\n",
            "Epoch 1/10\n",
            "2432/2432 [==============================] - 98s 37ms/step - loss: 10.4199 - accuracy: 0.0021\n",
            "Epoch 2/10\n",
            "2432/2432 [==============================] - 90s 37ms/step - loss: 11.6192 - accuracy: 0.0113\n",
            "Epoch 3/10\n",
            "2432/2432 [==============================] - 90s 37ms/step - loss: 10.6168 - accuracy: 0.0112\n",
            "Epoch 4/10\n",
            "2432/2432 [==============================] - 90s 37ms/step - loss: 10.1501 - accuracy: 0.0114\n",
            "Epoch 5/10\n",
            "2432/2432 [==============================] - 90s 37ms/step - loss: 10.1220 - accuracy: 0.0128\n",
            "Epoch 6/10\n",
            "2432/2432 [==============================] - 90s 37ms/step - loss: 10.1309 - accuracy: 0.0132\n",
            "Epoch 7/10\n",
            "2432/2432 [==============================] - 90s 37ms/step - loss: 9.9413 - accuracy: 0.0129\n",
            "Epoch 8/10\n",
            "2432/2432 [==============================] - 90s 37ms/step - loss: 9.8892 - accuracy: 0.0133\n",
            "Epoch 9/10\n",
            "2432/2432 [==============================] - 90s 37ms/step - loss: 10.1115 - accuracy: 0.0134\n",
            "Epoch 10/10\n",
            "2432/2432 [==============================] - 90s 37ms/step - loss: 9.7534 - accuracy: 0.0134\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Creating model (RNN)\n",
        "model2 = Sequential()\n",
        "model2.add(LSTM(units = 1000, input_shape = (window_size, len(x_train[0][0])), return_sequences = True))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(LSTM(units = 1000, return_sequences = True))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(LSTM(units = 1000))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(units = len(y_train[0])))\n",
        "\n",
        "# Showing properties\n",
        "model2.summary()\n",
        "\n",
        "# Setting the optimizer algorithm and compiling the model\n",
        "opt = Adagrad(learning_rate = 0.01)\n",
        "model2.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "print(\"Model2 ready\")\n",
        "\n",
        "# Training the model\n",
        "history2 = model2.fit(x_train, y_train, epochs=10, batch_size=16)\n",
        "# Saving the model\n",
        "model2.save(\"drive/MyDrive/Colab Notebooks/LSTM_3x1000_10epochs.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
